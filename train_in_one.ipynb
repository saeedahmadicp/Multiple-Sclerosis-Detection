{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Auto-Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms \u001b[39mas\u001b[39;00m t\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\root\\anaconda3\\envs\\torch-test\\Lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodulefinder\u001b[39;00m \u001b[39mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m \u001b[39mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\root\\anaconda3\\envs\\torch-test\\Lib\\site-packages\\torchvision\\models\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mswin_transformer\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmaxvit\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m detection, optical_flow, quantization, segmentation, video\n\u001b[0;32m     19\u001b[0m \u001b[39m# The Weights and WeightsEnum are developer-facing utils that we make public for\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# downstream libs like torchgeo https://github.com/pytorch/vision/issues/7094\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# TODO: we could / should document them publicly, but it's not clear where, as\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# they're not intended for end users.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m \u001b[39mimport\u001b[39;00m get_model, get_model_builder, get_model_weights, get_weight, list_models, Weights, WeightsEnum\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1026\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1148\u001b[0m, in \u001b[0;36mpath_stats\u001b[1;34m(self, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from utils import Fit\n",
    "from model import Decoder, Encoder\n",
    "from dataset import reshape_3d, get_train_ds_loader, get_test_ds_loader\n",
    "from dataset import visualize_data, spliting_data_5_folds, map_target_values_to_labels\n",
    "from loss import CombinedLoss\n",
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 50\n",
    "IMAGE_HEIGHT =  256\n",
    "IMAGE_WIDTH =   256\n",
    "IMAGE_DEPTH = 16\n",
    "\n",
    "DATASET_DIR = 'MS_Dataset'\n",
    "\n",
    "def main():\n",
    "    ## reshpae the volumes \n",
    "    reshape = reshape_3d(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, depth=IMAGE_DEPTH)\n",
    "    def reshape_volume(x): return reshape(x)\n",
    "    ##transforms\n",
    "    general_transform = t.Compose([\n",
    "       t.Lambda(reshape_volume),\n",
    "    ])\n",
    "    \n",
    "    ## spliting the data into 5 folds\n",
    "    folds_data = spliting_data_5_folds(DATASET_DIR)\n",
    "    \n",
    "    ## data loaders\n",
    "    for fold_index in range(1):\n",
    "        train_dl = get_train_ds_loader(dataset_dir=DATASET_DIR, data_dict=folds_data[fold_index], modality=\"FLAIR\", \n",
    "                                       transform=general_transform, target_transform=general_transform, batch_size=BATCH_SIZE)\n",
    "        test_dl = get_test_ds_loader(dataset_dir=DATASET_DIR, data_dict=folds_data[fold_index], modality=\"FLAIR\",\n",
    "                                     transform=general_transform, target_transform=general_transform, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        \n",
    "        ## loss function\n",
    "        loss_fn = CombinedLoss()\n",
    "        \n",
    "        ## define the model\n",
    "        encoder = Encoder(in_channels=1, filters=[32, 64, 128, 256, 512]).to(DEVICE)\n",
    "        decoder = Decoder(out_channels=1, filters=[32, 64, 128, 256, 512]).to(DEVICE)\n",
    "        \n",
    "        optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=LEARNING_RATE)\n",
    "        history = Fit(train_dl, test_dl, encoder, decoder, optimizer, loss_fn, DEVICE, epochs=NUM_EPOCHS)\n",
    "        \n",
    "        ## save the history in json file\n",
    "        os.makedirs('history', exist_ok=True)\n",
    "        history_path = os.path.join('history', f'history_fold_{fold_index}.json')\n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(history, f)\n",
    "            f.close()\n",
    "        \n",
    "        print(f\"Fold {fold_index} is done!\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from model import  Encoder, SclerosisClassifier\n",
    "from dataset import reshape_3d, get_train_ds_loader, get_test_ds_loader\n",
    "from dataset import  spliting_data_5_folds\n",
    "from classifier_utils import find_class_wise_accuracies\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 25\n",
    "IMAGE_HEIGHT =  256\n",
    "IMAGE_WIDTH =   256\n",
    "IMAGE_DEPTH = 16\n",
    "\n",
    "DATASET_DIR = 'MS_Dataset'\n",
    "\n",
    "def main():\n",
    "    ## reshpae the volumes \n",
    "    reshape = reshape_3d(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, depth=IMAGE_DEPTH)\n",
    "    def reshape_volume(x): return reshape(x)\n",
    "    ##transforms\n",
    "    general_transform = t.Compose([\n",
    "       t.Lambda(reshape_volume),\n",
    "    ])\n",
    "    \n",
    "    ## spliting the data into 5 folds\n",
    "    folds_data = spliting_data_5_folds(DATASET_DIR)\n",
    "    \n",
    "    ## data loaders\n",
    "    for fold_index in range(1):\n",
    "        train_dl = get_train_ds_loader(dataset_dir=DATASET_DIR, data_dict=folds_data[fold_index], modality=\"FLAIR\", \n",
    "                                       transform=general_transform, target_transform=general_transform, batch_size=BATCH_SIZE)\n",
    "        test_dl = get_test_ds_loader(dataset_dir=DATASET_DIR, data_dict=folds_data[fold_index], modality=\"FLAIR\",\n",
    "                                     transform=general_transform, target_transform=general_transform, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        \n",
    "        ## loss function\n",
    "        loss_fn = nn.MSELoss()\n",
    "        \n",
    "        ## define the model\n",
    "        encoder = Encoder(in_channels=1, filters=[32, 64, 128, 256, 512]).to(DEVICE)\n",
    "        \n",
    "        classifier = SclerosisClassifier(input_channels=512, ouptut_units=20).to(DEVICE)\n",
    "        optimizer = optim.Adam(classifier.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "        ## load the encoder weights\n",
    "        encoder_weights_path = os.path.join('models', 'encoder.pth')\n",
    "        encoder.load_state_dict(torch.load(encoder_weights_path))\n",
    "        \n",
    "        for param in encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        ## best accuracy\n",
    "        best_test_accuracy = 0.0\n",
    "        \n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            \n",
    "            for batch, (x, _, sp_data) in enumerate(train_dl):\n",
    "                x = x.to(DEVICE).unsqueeze(1)\n",
    "            \n",
    "            \n",
    "                ## get the features from the encoder\n",
    "                _, _, _, _, features = encoder(x)\n",
    "            \n",
    "                ## forward pass\n",
    "                sp_features = sp_data['features'].to(DEVICE)\n",
    "                sp_target = sp_data['target'].to(DEVICE)\n",
    "                outputs = classifier(features, sp_features)\n",
    "            \n",
    "                ## calculate the loss\n",
    "                loss = loss_fn(outputs, sp_target)\n",
    "            \n",
    "                ## backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            \n",
    "                ##culculate the accuracy for 20 classes\n",
    "                accuracy = []\n",
    "            \n",
    "                ## convert the probability to class\n",
    "                outputs = torch.round(outputs)\n",
    "                \n",
    "                if batch % 10 == 0:\n",
    "                    ## check the accuracy for each label sperately, muliti-class multi-label\n",
    "                    for class_i in range(20):\n",
    "                        accuracy.append((outputs[:, class_i] == sp_target[:, class_i]).sum().item())\n",
    "                    \n",
    "                    print('Epoch: {}/{}, Batch: {}/{}, Loss: {:.4f}, Accuracy: {}'.format(epoch+1, NUM_EPOCHS, batch+1, len(train_dl), loss.item(), np.mean(accuracy)))\n",
    "                    #print(np.mean(accuracy))\n",
    "            \n",
    "            ## calculate the accuracy for 20 classes for test data\n",
    "            train_accuracy = find_class_wise_accuracies(train_dl, classifier, encoder, DEVICE)\n",
    "            test_accuracy = find_class_wise_accuracies(test_dl, classifier, encoder, DEVICE)\n",
    "            \n",
    "            print('Train Accuracy: {}, Test Accuracy: {}'.format(np.mean(train_accuracy), np.mean(test_accuracy)))\n",
    "            \n",
    "            if np.mean(test_accuracy) > best_test_accuracy:\n",
    "                best_test_accuracy = np.mean(test_accuracy)\n",
    "                print('Saving the best model...')\n",
    "                ## save the model\n",
    "                path = os.path.join('models', 'classifier.pth')\n",
    "                torch.save(classifier.state_dict(), path)\n",
    "                \n",
    "        \n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Pyramidal, Label: 0, Accuracy: 41.67\n",
      "Class: Cerebella, Label: 1, Accuracy: 66.67\n",
      "Class: Brain stem, Label: 2, Accuracy: 83.33\n",
      "Class: Sensory, Label: 3, Accuracy: 50.0\n",
      "Class: Sphincters, Label: 4, Accuracy: 75.0\n",
      "Class: Visual, Label: 5, Accuracy: 58.33\n",
      "Class: Mental, Label: 6, Accuracy: 83.33\n",
      "Class: Speech, Label: 7, Accuracy: 83.33\n",
      "Class: Motor System, Label: 8, Accuracy: 58.33\n",
      "Class: Sensory System, Label: 9, Accuracy: 58.33\n",
      "Class: Coordination, Label: 10, Accuracy: 66.67\n",
      "Class: Gait, Label: 11, Accuracy: 75.0\n",
      "Class: Bowel and bladder function, Label: 12, Accuracy: 75.0\n",
      "Class: Mobility, Label: 13, Accuracy: 75.0\n",
      "Class: Mental State, Label: 14, Accuracy: 66.67\n",
      "Class: Optic discs, Label: 15, Accuracy: 58.33\n",
      "Class: Fields, Label: 16, Accuracy: 91.67\n",
      "Class: Nystagmus, Label: 17, Accuracy: 83.33\n",
      "Class: Ocular Movement, Label: 18, Accuracy: 83.33\n",
      "Class: Swallowing, Label: 19, Accuracy: 83.33\n",
      "\n",
      "Overall Mean Accuracy: 71.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from model import  Encoder, SclerosisClassifier\n",
    "from dataset import reshape_3d, get_train_ds_loader, get_test_ds_loader\n",
    "from dataset import  spliting_data_5_folds, map_target_values_to_labels\n",
    "from classifier_utils import find_class_wise_accuracies\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_HEIGHT =  256\n",
    "IMAGE_WIDTH =   256\n",
    "IMAGE_DEPTH = 16\n",
    "\n",
    "DATASET_DIR = 'MS_Dataset'\n",
    "\n",
    "def main():\n",
    "    ## reshpae the volumes \n",
    "    reshape = reshape_3d(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, depth=IMAGE_DEPTH)\n",
    "    def reshape_volume(x): return reshape(x)\n",
    "    ##transforms\n",
    "    general_transform = t.Compose([\n",
    "       t.Lambda(reshape_volume),\n",
    "    ])\n",
    "    \n",
    "    ## spliting the data into 5 folds\n",
    "    folds_data = spliting_data_5_folds(DATASET_DIR)\n",
    "    \n",
    "    ## data loaders\n",
    "    for fold_index in range(1):\n",
    "        test_dl = get_test_ds_loader(dataset_dir=DATASET_DIR, data_dict=folds_data[fold_index], modality=\"FLAIR\",\n",
    "                                     transform=general_transform, target_transform=general_transform, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        \n",
    "        ## define the models\n",
    "        encoder = Encoder(in_channels=1, filters=[32, 64, 128, 256, 512]).to(DEVICE) ## encoder\n",
    "        classifier = SclerosisClassifier(input_channels=512, ouptut_units=20).to(DEVICE) ## classifier\n",
    "        \n",
    "        \n",
    "        ## load the encoder weights\n",
    "        encoder_weights_path = os.path.join('models', 'encoder.pth')\n",
    "        \n",
    "        if DEVICE == 'cuda':\n",
    "            encoder.load_state_dict(torch.load(encoder_weights_path))\n",
    "        else:\n",
    "            encoder.load_state_dict(torch.load(encoder_weights_path, map_location=torch.device('cpu')))\n",
    "\n",
    "        ## load the classifier weights\n",
    "        classifier_weights_path = os.path.join('models', 'classifier.pth')\n",
    "        if DEVICE == 'cuda':\n",
    "            classifier.load_state_dict(torch.load(classifier_weights_path))\n",
    "        else:\n",
    "            classifier.load_state_dict(torch.load(classifier_weights_path, map_location=torch.device('cpu')))\n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "        ## test the model\n",
    "        accuracies = find_class_wise_accuracies(classifier=classifier, encoder=encoder,data_dl=test_dl, device=DEVICE)\n",
    "        \n",
    "        ## map the target values to labels\n",
    "        values = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11 ,12 ,13 ,14 ,15 ,16 ,17 ,18 ,19]\n",
    "        dict_map = map_target_values_to_labels(values=values, dataset_dir=DATASET_DIR)\n",
    "        \n",
    "        ## print the accuracies\n",
    "        for index, (key, value) in enumerate(dict_map.items()):\n",
    "            print(\"Class: {}, Label: {}, Accuracy: {}\".format(key, value, (round(accuracies[index] *100, 2))))\n",
    "        \n",
    "        print(\"\\nOverall Mean Accuracy: {}\\n\\n\".format(round(np.mean(accuracies), 2)*100))\n",
    "\n",
    "   \n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
